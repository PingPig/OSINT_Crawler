import asyncio
import json
import re
import random
import os
from playwright.async_api import async_playwright

# ================= é…ç½®åŒºåŸŸ =================
KEYWORD = "å“ˆå°”æ»¨ç”µæ°”é›†å›¢ è”ç³»æ–¹å¼"
TARGET_COUNT = 10
FILENAME = "sogou_sda_source_trace.json" # æ–‡ä»¶åæ”¹ä¸€ä¸‹ï¼Œä»£è¡¨å¸¦æº¯æº
HEADLESS = True  
# ===========================================

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', text).strip()

def extract_structured_data_with_source(full_text):
    lines = full_text.split('\n')
    
    # 1. ä¸¥æ ¼çš„å…¬å¸åæ­£åˆ™ (ç”¨äºè¯†åˆ«ç‹¬ç«‹çš„æ ‡é¢˜è¡Œ)
    re_company_strict = re.compile(r'^[\u4e00-\u9fa5()ï¼ˆï¼‰a-zA-Z0-9-]{4,35}(?:å…¬å¸|é›†å›¢|å‚|é™¢|ä¸­å¿ƒ|åº—|å±€|éƒ¨|ç¤¾|å§”å‘˜ä¼š|åˆ†å…¬å¸)$')
    
    # 2. ğŸ”¥ æ–°å¢ï¼šå®½æ¾çš„å…¬å¸åæ­£åˆ™ (ç”¨äºä»é•¿å¥å¼€å¤´æå–)
    # é€»è¾‘ï¼šåŒ¹é…è¡Œé¦–çš„å…¬å¸åï¼Œå³ä½¿åé¢æœ‰å…¶ä»–æ–‡å­—
    re_company_loose = re.compile(r'^([\u4e00-\u9fa5()ï¼ˆï¼‰a-zA-Z0-9-]{4,35}(?:å…¬å¸|é›†å›¢|å‚|é™¢|ä¸­å¿ƒ|åº—|å±€|éƒ¨|ç¤¾|å§”å‘˜ä¼š|åˆ†å…¬å¸))')

    re_person = re.compile(r'(?:è”ç³»äºº|å’¨è¯¢|æŠ¥å|äººäº‹|å¹²äº‹)[:ï¼š\s]*([\u4e00-\u9fa5]{2,4})')
    
    patterns = {
        "mobile": re.compile(r'(?<!\d)(1[3-9]\d{9})(?!\d)'),
        "email": re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'),
        "landline": re.compile(r'(?<!\d)(0\d{2,3}[- ]?\d{7,8})(?!\d)'),
        "wechat": re.compile(r'(?:å¾®ä¿¡|vx|WeChat)[:ï¼š\s]*([a-zA-Z][a-zA-Z\d_-]{5,19})', re.IGNORECASE)
    }

    blocks = []
    current_block = []
    
    # å¢åŠ ä¸€ä¸ªå…¨å±€å˜é‡è®°å½•æ–‡ç« ä¸­æœ€åƒå…¬å¸åçš„é‚£ä¸ªè¯ï¼ˆä½œä¸ºé»˜è®¤å€¼ï¼‰
    # å¦‚æœæŸä¸€æ®µæ‰¾ä¸åˆ°å…¬å¸åï¼Œå°±ç”¨è¿™ä¸ªå…¨å±€çš„
    global_company_candidate = "æœªè¯†åˆ«ä¸»ä½“"

    for line in lines:
        line = line.strip()
        if len(line) < 2: continue 

        is_new_block = False
        
        # ç­–ç•¥ A: ä¸¥æ ¼åŒ¹é… (æ•´è¡Œå°±æ˜¯å…¬å¸å)
        if re_company_strict.match(line) and "æ‹›è˜" not in line and "è”ç³»" not in line:
            is_new_block = True
            global_company_candidate = line # æ›´æ–°å…¨å±€å€™é€‰
        
        # ç­–ç•¥ B: å®½æ¾åŒ¹é… (è¡Œé¦–æ˜¯å…¬å¸å)
        # åªæœ‰å½“è¿™ä¸€è¡Œå¾ˆé•¿ï¼Œä¸”ä»¥å…¬å¸åå¼€å¤´æ—¶æ‰è§¦å‘
        elif len(line) > 35:
            match = re_company_loose.match(line)
            if match:
                # æå–å‡ºæ¥çš„å…¬å¸å
                extracted_name = match.group(1)
                # å¦‚æœè¿™ä¸ªåå­—çœ‹èµ·æ¥å¾ˆé è°±ï¼ˆä¸æ˜¯"æœ¬å…¬å¸"è¿™ç§ï¼‰ï¼Œå°±è®¤é¢†
                if len(extracted_name) > 6:
                    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸ä¸€å®šè¦åˆ‡åˆ† Blockï¼Œå› ä¸ºé•¿æ®µè½é€šå¸¸åŒ…å«æ­£æ–‡
                    # æˆ‘ä»¬åªæ˜¯æ›´æ–°å…¨å±€å€™é€‰ï¼Œæ–¹ä¾¿åé¢çš„ç”µè¯æŒ‚é 
                    global_company_candidate = extracted_name

        if is_new_block:
            if current_block:
                blocks.append(current_block)
            current_block = [line]
        else:
            current_block.append(line)
    
    if current_block:
        blocks.append(current_block)

    results = []
    
    for block in blocks:
        block_text = "\n".join(block)
        
        # ç¡®å®šä¸»ä½“ï¼šä¼˜å…ˆçœ‹å—çš„ç¬¬ä¸€è¡Œï¼Œå¦‚æœä¸è¡Œï¼Œå°±ç”¨å…¨å±€å€™é€‰
        first_line = block[0]
        if re_company_strict.match(first_line) and "æ‹›è˜" not in first_line:
            entity = first_line
        else:
            # ğŸ”¥ ä½¿ç”¨å…¨å±€æŠ“å–åˆ°çš„å…¬å¸åå…œåº•
            entity = global_company_candidate

        contact_person = "æœªçŸ¥"
        for line in block:
            p_match = re_person.search(line)
            if p_match:
                contact_person = p_match.group(1)
                break

        for line in block:
            if "é‚®ç¼–" in line: continue
            
            for p_type, regex in patterns.items():
                matches = regex.findall(line)
                for val in matches:
                    if p_type == 'wechat':
                        if val.lower() in ['jpg', 'png', 'pdf', 'doc', 'com', 'cn', 'net']: continue

                    results.append({
                        "entity": entity,
                        "contact_person": contact_person,
                        "type": p_type,
                        "value": val,
                        "context": line,
                        "origin_data": block_text
                    })

    # å»é‡
    unique_results = []
    seen = set()
    for r in results:
        fingerprint = f"{r['entity']}_{r['type']}_{r['value']}"
        if fingerprint not in seen:
            seen.add(fingerprint)
            unique_results.append(r)

    return unique_results

async def run():
    print(f"[*] å¯åŠ¨æº¯æºé‡‡é›†å™¨...")
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=HEADLESS, args=['--disable-blink-features=AutomationControlled'])
        context = await browser.new_context(viewport={'width': 1920, 'height': 1080}, user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        await context.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        page = await context.new_page()
        print(f"[*] æ­£åœ¨æœç´¢: {KEYWORD}")
        await page.goto(f"https://weixin.sogou.com/weixin?type=2&query={KEYWORD}&ie=utf8", wait_until="domcontentloaded")
        
        if "antispider" in page.url or "éªŒè¯ç " in await page.content():
            print("âš ï¸  è§¦å‘éªŒè¯ç ã€‚")
            await browser.close()
            return

        data_list = []
        try: await page.wait_for_selector(".news-list li", timeout=5000)
        except: return

        search_results = await page.query_selector_all(".news-list li")
        print(f"[*] æ‰¾åˆ° {len(search_results)} ç¯‡æ–‡ç« ...")

        for i, item in enumerate(search_results):
            if i >= TARGET_COUNT: break
            try:
                title_el = await item.query_selector("h3 a")
                title = await title_el.inner_text()
                account_el = await item.query_selector(".s-p")
                account = await account_el.inner_text() if account_el else "æœªçŸ¥"
                
                print(f"\n[{i+1}/{TARGET_COUNT}] è§£ææ–‡ç« : {title[:20]}...")
                async with context.expect_page() as new_page_info: await title_el.click()
                article_page = await new_page_info.value
                try: await article_page.wait_for_selector("#js_content", timeout=8000)
                except: continue
                
                content_element = await article_page.query_selector("#js_content")
                if not content_element: content_element = await article_page.query_selector("body")
                full_text = await content_element.inner_text()
                
                # ğŸ”¥ è°ƒç”¨åˆ†å—æå–å‡½æ•°
                contacts = extract_structured_data_with_source(full_text)
                
                if contacts:
                    print(f"    âœ… æå–åˆ° {len(contacts)} æ¡æ•°æ®")
                    # æ‰“å°ç¬¬ä¸€æ¡æ•°æ®çœ‹çœ‹ origin_data æ•ˆæœ
                    if len(contacts) > 0:
                        print(f"       ç¤ºä¾‹æº¯æº:\n{contacts[0]['origin_data'][:100]}...") # æ‰“å°å‰100å­—
                
                data_list.append({
                    "title": title,
                    "account": account,
                    "url": article_page.url,
                    "extracted_data": contacts
                })

                await article_page.close()
                await asyncio.sleep(random.uniform(2, 4))
            except Exception as e: continue

        with open(FILENAME, 'w', encoding='utf-8') as f:
            json.dump(data_list, f, ensure_ascii=False, indent=4)
        print(f"\n[*] æº¯æºæ•°æ®å·²ä¿å­˜è‡³: {FILENAME}")
        await browser.close()

if __name__ == "__main__":
    asyncio.run(run())