import asyncio
import json
import random
import os
import re
from playwright.async_api import async_playwright

# ==========================================
# ğŸ‘‡ğŸ‘‡ğŸ‘‡ ã€ç”¨æˆ·é…ç½®åŒºåŸŸã€‘ ğŸ‘‡ğŸ‘‡ğŸ‘‡
# ==========================================

CONFIG = {
    "keyword": "æµ‹è¯•ç›®æ ‡",        
    "target_count": 20,          
    "save_file_name": "users_cleaned.json",
    "headless_mode": True 
}

# ==========================================
# ğŸ‘†ğŸ‘†ğŸ‘† é…ç½®ç»“æŸ ğŸ‘†ğŸ‘†ğŸ‘†
# ==========================================

def clean_text(text):
    if not text:
        return ""
    return re.sub(r'\s+', ' ', text).strip()

def extract_info(raw_data):
    """
    æå–é€»è¾‘ä¿®æ­£ç‰ˆ V7ï¼š
    1. æ˜µç§° & ç®€ä»‹æ¸…æ´— (V6é€»è¾‘ä¿æŒ)
    2. è”ç³»æ–¹å¼æå– (V6é€»è¾‘ä¿æŒ)
    3. ğŸ”¥ æ–°å¢ï¼šç²‰ä¸æ•° & è·èµæ•°æå–
    """
    cleaned_list = []
    
    # --- æ­£åˆ™è¡¨è¾¾å¼ ---

    # 1. æ˜µç§°åˆ‡å‰²
    re_nickname_clean = re.compile(r'^(.+?)(?=\s+(?:å…³æ³¨|æŠ–éŸ³å·|è®¤è¯å¾½ç« ))')

    # 2. ç®€ä»‹åˆ‡å‰²
    re_bio_after_stats = re.compile(r'(?:ç²‰ä¸|è·èµ|å…³æ³¨)\s+(.*)')
    re_bio_after_id = re.compile(r'æŠ–éŸ³å·[:ï¼š]\s*[a-zA-Z0-9_.-]+\s+(.*)')

    # 3. æŠ–éŸ³å·
    re_douyin = re.compile(r'æŠ–éŸ³å·[:ï¼š]\s*([a-zA-Z0-9_.-]+)')

    # 4. ğŸ”¥ ç²‰ä¸æ•° & è·èµæ•° (æ–°å¢)
    # åŒ¹é…é€»è¾‘ï¼šæ•°å­— + å¯é€‰çš„å°æ•°ç‚¹ + å¯é€‰çš„å•ä½(ä¸‡/w/W/äº¿) + å…³é”®è¯
    # ä¾‹å­ï¼š1.8ä¸‡è·èµ, 3686ç²‰ä¸, 1.2wè·èµ
    re_likes = re.compile(r'(\d+(?:\.\d+)?[ä¸‡wWäº¿]?)\s*è·èµ')
    re_followers = re.compile(r'(\d+(?:\.\d+)?[ä¸‡wWäº¿]?)\s*ç²‰ä¸')

    # 5. è”ç³»æ–¹å¼æ­£åˆ™ç»„
    re_mobile_loose = re.compile(r'(?:æ‰‹æœº|ç”µè¯|è”ç³»|V|VX|vx|å¾®ä¿¡|åˆä½œ)[:ï¼š]?\s*(1[3-9](?:[\s-]*\d){9})')
    re_landline = re.compile(r'(?<!\d)(0\d{2,3}[-\s]?\d{7,8})(?!\d)')
    re_hotline = re.compile(r'(?<!\d)(400[-\s]?\d{3}[-\s]?\d{4})(?!\d)')
    re_wechat = re.compile(r'(?:å¾®ä¿¡|V|VX|vx|å¾®)[:ï¼š]?\s*([a-zA-Z][a-zA-Z0-9_-]{5,19})')
    re_qq = re.compile(r'(?:QQ|qq|Q)[:ï¼š]?\s*(\d{5,11})')
    re_email = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}')

    for item in raw_data:
        # è·å–æœ€å…¨çš„æ–‡æœ¬
        raw_text = item.get('details', '') 
        if len(item.get('nickname', '')) > len(raw_text):
            raw_text = item.get('nickname', '')
        
        # ç»Ÿä¸€ç¬¦å·
        raw_text = clean_text(raw_text).replace('ï¼š', ':')
        
        # --- ğŸ…°ï¸ æ˜µç§°æ¸…æ´— ---
        nickname_match = re_nickname_clean.search(raw_text)
        nickname = nickname_match.group(1).strip() if nickname_match else raw_text[:20].strip()

        # --- ğŸ…±ï¸ æŠ–éŸ³å·æå– ---
        douyin_match = re_douyin.search(raw_text)
        douyin_id = douyin_match.group(1) if douyin_match else "æœªæ‰¾åˆ°"

        # --- ğŸ…¾ï¸ ç²‰ä¸æ•° & è·èµæ•°æå– (æ–°å¢) ---
        likes_match = re_likes.search(raw_text)
        likes = likes_match.group(1) if likes_match else "0"

        followers_match = re_followers.search(raw_text)
        followers = followers_match.group(1) if followers_match else "0"

        # --- Â©ï¸ ç®€ä»‹æ¸…æ´— ---
        bio = ""
        bio_stats_match = re_bio_after_stats.search(raw_text)
        if bio_stats_match:
            bio = bio_stats_match.group(1).strip()
        else:
            bio_id_match = re_bio_after_id.search(raw_text)
            bio = bio_id_match.group(1).strip() if bio_id_match else ""

        # --- ğŸ…¾ï¸ è”ç³»æ–¹å¼æå– ---
        raw_mobiles = re_mobile_loose.findall(raw_text)
        clean_mobiles = [re.sub(r'[\s-]', '', m) for m in raw_mobiles]

        all_landlines = list(set(re_landline.findall(raw_text) + re_hotline.findall(raw_text)))
        wechat_match = re_wechat.findall(raw_text)
        qq_match = re_qq.findall(raw_text)
        email_match = re_email.findall(raw_text)
        
        cleaned_item = {
            "nickname": nickname,
            "douyin_id": douyin_id,
            "description": bio,
            "profile_url": item.get('profileUrl', ''),
            # ğŸ”¥ æ–°å¢ stats å­—æ®µ
            "stats": {
                "likes": likes,
                "followers": followers
            },
            "contacts": {
                "mobile": list(set(clean_mobiles)),
                "landline": all_landlines,
                "wechat": list(set(wechat_match)),
                "qq": list(set(qq_match)),
                "email": list(set(email_match))
            }
        }
        cleaned_list.append(cleaned_item)
        
    return cleaned_list

async def run():
    # ... (ä¸»ç¨‹åºé€»è¾‘ä¿æŒä¸å˜ï¼Œå¤åˆ¶ V6 çš„ run å‡½æ•°å³å¯) ...
    user_data_dir = os.path.join(os.getcwd(), 'douyin_user_data')
    if not os.path.exists(user_data_dir):
        os.makedirs(user_data_dir)

    print(f'ğŸš€ å¯åŠ¨ä»»åŠ¡...')
    async with async_playwright() as p:
        context = await p.chromium.launch_persistent_context(
            user_data_dir,
            channel="chrome",
            headless=CONFIG["headless_mode"],
            viewport={'width': 1920, 'height': 1080},
            args=['--start-maximized', '--no-sandbox', '--disable-blink-features=AutomationControlled', '--ignore-certificate-errors'],
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )
        page = context.pages[0]
        await page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        try:
            await page.goto("https://www.douyin.com", wait_until='domcontentloaded')
        except: pass

        if not CONFIG["headless_mode"]:
            input("ğŸ‘‰ ç¡®è®¤ç™»å½•å°±ç»ªåï¼Œè¯·æŒ‰ã€å›è½¦é”®ã€‘ç»§ç»­...")
        else:
            await asyncio.sleep(3)

        search_url = f"https://www.douyin.com/search/{CONFIG['keyword']}?type=user"
        await page.goto(search_url, wait_until='domcontentloaded')
        await asyncio.sleep(3)

        unique_users_map = {}
        no_new_data_count = 0
        
        print('â¬‡ï¸ å¼€å§‹æŠ“å–æ•°æ®...')

        while len(unique_users_map) < CONFIG['target_count']:
            current_batch = await page.evaluate('''() => {
                function getTextWithSpaces(node) {
                    if (node.nodeType === 3) return node.nodeValue;
                    if (node.nodeType === 1) {
                        let s = "";
                        node.childNodes.forEach(child => s += getTextWithSpaces(child));
                        return s + " "; 
                    }
                    return "";
                }
                const items = [];
                const userLinks = document.querySelectorAll('a[href*="/user/"]');
                userLinks.forEach(link => {
                    const href = link.href;
                    const text = getTextWithSpaces(link).trim(); 
                    if (href.includes('/user/') && !href.includes('self') && !href.includes('from_nav')) {
                        if (text.length > 0) {
                            items.push({
                                'nickname': text, 
                                'profileUrl': href.split('?')[0], 
                                'details': text 
                            });
                        }
                    }
                });
                return items;
            }''')

            size_before = len(unique_users_map)
            for user in current_batch:
                url = user['profileUrl']
                if url not in unique_users_map:
                    unique_users_map[url] = user
                else:
                    if len(user['details']) > len(unique_users_map[url]['details']):
                        unique_users_map[url] = user
            
            size_after = len(unique_users_map)
            print(f"ğŸ“Š å½“å‰æœ‰æ•ˆç”¨æˆ·: {size_after} / {CONFIG['target_count']}")

            if size_after >= CONFIG['target_count']: break
            if size_after == size_before:
                no_new_data_count += 1
                if no_new_data_count > 5: break
            else:
                no_new_data_count = 0 

            await page.evaluate('window.scrollBy(0, document.body.scrollHeight)')
            await asyncio.sleep(random.uniform(2.0, 4.0))

        raw_data = list(unique_users_map.values())[:CONFIG['target_count']]
        
        print("ğŸ§¹ æ­£åœ¨è¿›è¡Œæ•°æ®æ¸…æ´—å’Œæå–...")
        final_data = extract_info(raw_data)

        with open(CONFIG['save_file_name'], 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… æ•°æ®å·²æ¸…æ´—å¹¶ä¿å­˜: {CONFIG['save_file_name']}")

if __name__ == '__main__':
    asyncio.run(run())